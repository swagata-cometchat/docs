---
title: "Build Your Group Chat Agent with Mastra"
sidebarTitle: "Group Chat Agent"
description: "Follow these steps to create a Group Chat Agent in Mastra that can join group conversations and provide answers or actions when invoked."
---

Imagine an agent that sits quietly in a group chat until someone calls on it. Ask `@helper what’s our refund policy?` and the agent responds with the correct info, without interrupting the ongoing human conversation.

***

## What You’ll Build

* A **Mastra agent** that can participate in group conversations.  
* Triggered only when explicitly mentioned (e.g., `@agent`).  
* Can fetch knowledge, trigger tools, or summarize discussions.  
* Optional: integrate into **CometChat** group chats.  

***

## Prerequisites

* A Mastra project (`npx create-mastra@latest my-mastra-app`).  
* Node.js installed.  
* OpenAI API key in `.env` as `OPENAI_API_KEY`.  
* A CometChat app with group chat enabled.  

***

<h3 className="text-2xl font-semibold mb-6 mt-8">
  <span className="inline-flex items-center px-4 py-1.5 rounded-full bg-emerald-100 text-emerald-700 dark:bg-emerald-900/30 dark:text-emerald-300 uppercase tracking-wide text-sm">Step 1</span>
</h3>

## Create the Agent

**`src/agents/group-chat-agent.ts`**:

```ts
import { openai } from '@ai-sdk/openai';
import { Agent } from '@mastra/core/agent';

export const groupChatAgent = new Agent({
  name: 'Group Chat Agent',
  instructions: `
You are a helpful assistant in a group chat. 
- Only respond when explicitly mentioned with @agent.
- Keep answers short and relevant.
- If unclear, say "I don’t know" rather than guessing.
  `,
  model: openai('gpt-4o-mini'),
});
```

***

<h3 className="text-2xl font-semibold mb-6 mt-8">
  <span className="inline-flex items-center px-4 py-1.5 rounded-full bg-emerald-100 text-emerald-700 dark:bg-emerald-900/30 dark:text-emerald-300 uppercase tracking-wide text-sm">Step 2</span>
</h3>

## Register the Agent in Mastra

**`src/mastra/index.ts`**:

```ts
import { Mastra } from '@mastra/core/mastra';
import { PinoLogger } from '@mastra/loggers';
import { LibSQLStore } from '@mastra/libsql';

import { groupChatAgent } from '../agents/group-chat-agent';

export const mastra = new Mastra({
  agents: { 'group-chat': groupChatAgent }, // API path: /api/agents/group-chat/*
  storage: new LibSQLStore({ url: 'file:../mastra.db' }),
  logger: new PinoLogger({ name: 'Mastra', level: 'info' }),
});
```

***

<h3 className="text-2xl font-semibold mb-6 mt-8">
  <span className="inline-flex items-center px-4 py-1.5 rounded-full bg-emerald-100 text-emerald-700 dark:bg-emerald-900/30 dark:text-emerald-300 uppercase tracking-wide text-sm">Step 3</span>
</h3>

## Run the Agent

```bash
rm -rf .mastra/output
npx mastra dev
```

You should see:

```
Mastra API running on port http://localhost:4111/api
```

Test it locally:

```bash
curl -X POST http://localhost:4111/api/agents/group-chat/generate   -H "Content-Type: application/json"   -d '{"messages":[{"role":"user","content":"@agent what is our refund policy?"}]}'
```

Expected output:

```json
{ "reply": "Refunds are available within 30 days of purchase." }
```

***

<h3 className="text-2xl font-semibold mb-6 mt-8">
  <span className="inline-flex items-center px-4 py-1.5 rounded-full bg-emerald-100 text-emerald-700 dark:bg-emerald-900/30 dark:text-emerald-300 uppercase tracking-wide text-sm">Step 4</span>
</h3>

## Deploy & Connect

* Deploy the API (`/api/agents/group-chat/generate`) using Render, Railway, Vercel, or any host.  
* In **CometChat Dashboard → AI Agents**, create an agent with:  
  * **Provider**: Mastra  
  * **Agent ID**: `group-chat`  
  * **Deployment URL**: public endpoint from your host  

Now the agent will join group chats but only answer when mentioned.  

***

## Troubleshooting

* **Agent talks too much**: Tighten instructions to only respond when invoked.  
* **Doesn’t respond to mentions**: Ensure input message contains `@agent` keyword.  
* **Not visible in chat**: Verify the agent is added as a user in CometChat and enabled in the Dashboard.  

***

## Next Steps

* Extend the agent with tools (e.g., `summarize-discussion`, `fetch-policy`).  
* Add guardrails so the agent only responds to whitelisted topics.  
* Use in combination with a Multi-agent Orchestration (relay) agent to query multiple humans/agents.  
